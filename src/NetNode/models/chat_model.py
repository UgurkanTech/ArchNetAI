from .net_model import NetModel
from utils.tools import *

class ChatModel(NetModel):
    """
    Represents a chat model that interacts with a host and generates responses using a specified model.

    Args:
        host (Host): The host object representing the connection to the model server.
        model (str): The name or ID of the model to use for generating responses.

    Attributes:
        client (Client): The client object representing the connection to the model server.
        options (dict): The options to be used for generating responses.

    Methods:
        setOptions: Sets the options for generating responses.
        getModelResponse: Generates a response from the model given a context.
        ChatInteractive: Starts an interactive chat session with the model.
        printStream: Prints the generated response stream.

    """

    def __init__(self, host, model):
        super().__init__(host, model)
        self.client = self.host.client

    def setOptions(self, options):
        """
        Sets the options for generating responses.

        Args:
            options (dict): The options to be used for generating responses.

        """
        self.options = options

    def getModelResponse(self, context):
        """
        Generates a response from the model given a context.

        Args:
            context (str): The context or prompt for generating the response.

        Returns:
            stream: The response stream generated by the model.

        """
        stream = self.client.generate(
            model=self.model,
            prompt=context,
            images=[],
            stream=True,
            options=self.options,
            keep_alive='1m'
        )
        return stream

    def ChatInteractive(self):
        """
        Starts an interactive chat session with the model.

        The user can input prompts and receive responses from the model until they enter "exit".

        """
        while True:
            prompt = input("You: ")
            if prompt.lower() == "exit":
                break
            try:
                print("AI: ", end='')
                self.printStream(self.getModelResponse(prompt))
            except Exception as e:
                print("An error occurred: ", str(e))

    def printStream(self, stream):
        """
        Prints the generated response stream.

        Args:
            stream: The response stream generated by the model.

        """
        timer = Timer()
        for chunk in stream:
            print(chunk['response'], end='', flush=True)
            if 'usage' in chunk:
                print(f"\nTokens used: {chunk['usage']['total_tokens']}")
        print()
        timer.print_time()